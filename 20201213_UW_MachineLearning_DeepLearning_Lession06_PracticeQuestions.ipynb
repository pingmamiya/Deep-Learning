{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20201213_UW_MachineLearning_DeepLearning_Lession06_PracticeQuestions.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92aZRlmVVLhL"
      },
      "source": [
        "### For the Practice excercise for Lession 06: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yu7Va4-QVWz2"
      },
      "source": [
        "In this exercise we will examine the outputs from simple untrained LSTM and GRU networks, in order to better understand the Keras API.\n",
        "\n",
        "There are four parts, and 12 short questions to answer as you run the code below:\n",
        "\n",
        "1. LSTM: run with return_sequences=False\n",
        "2. LSTM: run with return_sequences=True\n",
        "3. GRU: run with return_sequences=False\n",
        "4. GRU: run with return_sequences=True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0Ed2l2ZVCmT",
        "outputId": "794f6403-db9f-4d1d-8550-617552af1809"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, GRU\n",
        "import numpy as np\n",
        "\n",
        "timesteps = 8\n",
        "num_features = 2\n",
        "num_nodes = 3\n",
        "\n",
        "#Create some random data\n",
        "data = np.random.randn(1, timesteps, num_features)\n",
        "print(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[-1.28875918  0.35352327]\n",
            "  [-0.91360787  1.03423392]\n",
            "  [ 0.97712755  1.07813044]\n",
            "  [-0.84268605  0.81410969]\n",
            "  [-0.72858672  0.66930141]\n",
            "  [-1.0776233  -1.19782537]\n",
            "  [ 0.32717254 -0.34321601]\n",
            "  [-0.42937633 -0.19439394]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "904dLCDiV2dN",
        "outputId": "fa14a4f3-9bae-4511-fb82-c796886b0a1a"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 8, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_MQB9FhWKFw"
      },
      "source": [
        "Q1: What do the dimensions of the data represent? E.g., what do the 1st dimension, the 2nd, and the 3rd represent here?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGdsFl02WNcQ"
      },
      "source": [
        "1st dimension: batch size (=1)\n",
        "2nd dimension: timesteps (=8)\n",
        "3rd dimension: number of features (=2) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8guoHQBWJmH",
        "outputId": "88fe88c4-7fd2-4363-d782-a57a9173e1fb"
      },
      "source": [
        "#LSTM: run with return_sequence = False\n",
        "\n",
        "inputs = Input(shape=(timesteps, num_features))\n",
        "rnn = LSTM (num_nodes, return_state = True)\n",
        "x = rnn(inputs)\n",
        "\n",
        "model = Model(inputs=inputs, outputs = x)\n",
        "\n",
        "output, h, c = model.predict(data)\n",
        "\n",
        "print(\"output:\", output)\n",
        "print(\"h:\", h)\n",
        "print(\"c:\", c)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output: [[-0.25732717 -0.12740867  0.14300866]]\n",
            "h: [[-0.25732717 -0.12740867  0.14300866]]\n",
            "c: [[-0.52285177 -0.2680984   0.2633277 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTou8HgzaLQi"
      },
      "source": [
        "Q2: What do these \"predict\" return values (output, h, and c) represent? Describe what they mean."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0puLZoZ7aOLO"
      },
      "source": [
        "Q3: What are the dimensions of output, h, and c?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmqLurLxWCQH",
        "outputId": "b587bbb6-e624-4002-cf34-cd6acccfea1a"
      },
      "source": [
        "output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qADPymiwcGxo",
        "outputId": "b54dab8b-aa6d-43a5-bf03-340e8734a6e8"
      },
      "source": [
        "h.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PB-u0YPTcJGq",
        "outputId": "3ac8fb64-b76b-4ee2-fba4-2cb5394b1437"
      },
      "source": [
        "c.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTcmLQH9cvw7"
      },
      "source": [
        "Q4: Is there any duplication among the values of (output, h, c)? If so, explain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzubfVy2fDHU"
      },
      "source": [
        "Q5: Change the LSTM to use \"return_state=False\" and modify the code accordingly to avoid errors. What does the LSTM return now?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckM7ATIncJ4M",
        "outputId": "83b5a191-628f-4489-9e9b-cf9a98854ffb"
      },
      "source": [
        "#LSTM: run with return_state = False\n",
        "\n",
        "inputs = Input(shape=(timesteps, num_features))\n",
        "rnn = LSTM (num_nodes, return_state = False)\n",
        "x = rnn(inputs)\n",
        "\n",
        "model = Model(inputs=inputs, outputs = x)\n",
        "\n",
        "output = model.predict(data)\n",
        "\n",
        "print(\"output:\", output)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output: [[-0.15197638  0.01377018 -0.07396807]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuehzbnKfQug"
      },
      "source": [
        "Run with return_sequence = True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXrkKI2reklJ",
        "outputId": "126d4787-f29a-432c-9590-b99f7fed5758"
      },
      "source": [
        "#LSTM: run with return_sequence = False\n",
        "\n",
        "inputs = Input(shape=(timesteps, num_features))\n",
        "rnn = LSTM (num_nodes, return_sequences= True, return_state = True)\n",
        "x = rnn(inputs)\n",
        "\n",
        "model = Model(inputs=inputs, outputs = x)\n",
        "\n",
        "output, h, c = model.predict(data)\n",
        "\n",
        "print(\"output:\", output)\n",
        "print(\"h:\", h)\n",
        "print(\"c:\", c)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f06833d49d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "output: [[[-0.05612301 -0.06896988 -0.18579502]\n",
            "  [-0.1875263  -0.06667361 -0.32710493]\n",
            "  [-0.17990069  0.13244492 -0.1955806 ]\n",
            "  [-0.29050726  0.03078281 -0.41637388]\n",
            "  [-0.28513885  0.01093456 -0.4316702 ]\n",
            "  [-0.09143886 -0.0999801  -0.36889783]\n",
            "  [-0.02488659  0.03234047 -0.14718549]\n",
            "  [-0.01412397 -0.02643303 -0.12061352]]]\n",
            "h: [[-0.01412397 -0.02643303 -0.12061352]]\n",
            "c: [[-0.02710348 -0.05504766 -0.21965176]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soYRPJ2af0-r"
      },
      "source": [
        "Q6: Now, what are the dimensions of output, h, and c?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjMD1zYnf46K"
      },
      "source": [
        "Q7: What does the output variable represent now? Explain the dimensions of the returned matrix (e.g., what does the 1st dimension represent? What does the 2nd represent? The 3rd? etc.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8N9e-zvfmOF",
        "outputId": "423b9e6f-87bd-4f25-cd02-fd1402022408"
      },
      "source": [
        "output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 8, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ry26PJoOgXM-"
      },
      "source": [
        "GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnOsJN9GgBhK",
        "outputId": "49ab1305-4f71-487d-a0bb-110abc9f52e7"
      },
      "source": [
        "inputs = Input(shape=(timesteps, num_features))\n",
        "\n",
        "rnn = GRU(num_nodes, return_state=True)\n",
        "\n",
        "x = rnn(inputs)\n",
        "\n",
        " \n",
        "\n",
        "model = Model(inputs=inputs, outputs=x)\n",
        "\n",
        "output, h = model.predict(data)\n",
        "\n",
        "print(\"o:\", output)\n",
        "\n",
        "print(\"h:\", h)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f06821dac80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "o: [[-0.29243028  0.41559392 -0.12007254]]\n",
            "h: [[-0.29243028  0.41559392 -0.12007254]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gh1yEWpkhkJF"
      },
      "source": [
        "Q8: What happened to the variable \"c\"? Why does the GRU only return a tuple of 2 values as opposed to 3?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEVMeoJThncR"
      },
      "source": [
        "Q9: What are the dimension of output and h?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpyowTOygdxx",
        "outputId": "7a66dd88-e7b6-4e99-dcd4-884b6af4c4e4"
      },
      "source": [
        "output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oG_WvD3BhuSj",
        "outputId": "2c7cf4d7-4205-4a47-8fdb-7857fb99c7cb"
      },
      "source": [
        "h.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0bcfOPDh03K"
      },
      "source": [
        "Q10: Is there any duplication between the values of output and h? If so, explain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpJKYpMSiVsd"
      },
      "source": [
        "Run with return_sequences=True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvAWajR4hy1U",
        "outputId": "1fc23b7b-9817-40c7-dec1-f855a6fd8cb8"
      },
      "source": [
        "inputs = Input(shape=(timesteps, num_features))\n",
        "\n",
        "rnn = GRU(num_nodes, return_sequences=True, return_state=True)\n",
        "\n",
        "x = rnn(inputs)\n",
        "\n",
        " \n",
        "\n",
        "model = Model(inputs=inputs, outputs=x)\n",
        "\n",
        "output, h = model.predict(data)\n",
        "\n",
        "print(\"o:\", output)\n",
        "\n",
        "print(\"h:\", h)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f06818156a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "o: [[[ 0.0309521   0.36112666 -0.2695216 ]\n",
            "  [-0.201059    0.5110463  -0.52815104]\n",
            "  [-0.40577215  0.1851165  -0.12411187]\n",
            "  [-0.41022527  0.36255985 -0.43215796]\n",
            "  [-0.35124218  0.48350626 -0.5538353 ]\n",
            "  [ 0.3398422   0.6222069  -0.47628465]\n",
            "  [ 0.3386014   0.24319556 -0.12537238]\n",
            "  [ 0.35191953  0.3164274  -0.1449812 ]]]\n",
            "h: [[ 0.35191953  0.3164274  -0.1449812 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-6T3ZCtionV"
      },
      "source": [
        "Q11: Now, what are the dimensions of output and h?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNvGBHQMiqQ2"
      },
      "source": [
        "Q12: Is there any duplication within the values of output and h? If so, explain. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAiZ6IV8iB0S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}